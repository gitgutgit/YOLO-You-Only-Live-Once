"""
Training Data Collector - ì›¹ ê²Œì„ì—ì„œ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘

GCP ì›¹ì—ì„œ ìœ ì €ë“¤ì´ í”Œë ˆì´í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥
ì œì´ì™€ í´ë¡œê°€ í›ˆë ¨ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬

Author: Minsuk Kim (mk4434)
"""

import os
import json
import time
from datetime import datetime
from pathlib import Path
import numpy as np
from typing import Dict, List, Any


class TrainingDataCollector:
    """
    í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ê¸°
    
    ì—­í• :
    1. ì›¹ ê²Œì„ì—ì„œ ìƒì„±ëœ ë°ì´í„° ìˆ˜ì§‘
    2. ì œì´(CV)ì™€ í´ë¡œ(AI)ê°€ ì‚¬ìš©í•  í˜•ì‹ìœ¼ë¡œ ì €ì¥
    3. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ë° í†µê³„
    """
    
    def __init__(self, data_dir: str = "data/gameplay"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.raw_dir = self.data_dir / "raw"
        self.processed_dir = self.data_dir / "processed"
        self.cv_training_dir = self.data_dir / "cv_training"  # ì œì´ìš©
        self.rl_training_dir = self.data_dir / "rl_training"  # í´ë¡œìš©
        
        for dir_path in [self.raw_dir, self.processed_dir, 
                         self.cv_training_dir, self.rl_training_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # í†µê³„
        self.stats = {
            'total_sessions': 0,
            'total_frames': 0,
            'total_actions': 0,
            'human_sessions': 0,
            'ai_sessions': 0
        }
        
        self.load_stats()
    
    def save_gameplay_session(self, session_data: Dict[str, Any]) -> str:
        """
        ê²Œì„í”Œë ˆì´ ì„¸ì…˜ ì €ì¥
        
        Args:
            session_data: ê²Œì„ ì„¸ì…˜ ë°ì´í„°
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # ì„¸ì…˜ ID ìƒì„±
        session_id = session_data.get('sessionId', f"session_{int(time.time())}")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        mode = session_data.get('mode', 'unknown')
        
        # Raw ë°ì´í„° ì €ì¥
        raw_file = self.raw_dir / f"{timestamp}_{session_id}_{mode}.json"
        with open(raw_file, 'w') as f:
            json.dump(session_data, f, indent=2)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.update_stats(session_data)
        
        # í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜
        self.process_for_training(session_data, session_id, timestamp)
        
        print(f"âœ… ì„¸ì…˜ ì €ì¥ ì™„ë£Œ: {raw_file.name}")
        print(f"   - í”„ë ˆì„: {len(session_data.get('frames', []))}")
        print(f"   - ì•¡ì…˜: {len(session_data.get('actions', []))}")
        print(f"   - ëª¨ë“œ: {mode}")
        
        return str(raw_file)
    
    def process_for_training(self, session_data: Dict, session_id: str, timestamp: str):
        """
        í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜ ë° ì €ì¥
        
        ì œì´(CV)ì™€ í´ë¡œ(AI)ê°€ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        mode = session_data.get('mode', 'unknown')
        
        # 1. CV í›ˆë ¨ ë°ì´í„° (ì œì´ìš©)
        self.save_cv_training_data(session_data, session_id, timestamp, mode)
        
        # 2. RL í›ˆë ¨ ë°ì´í„° (í´ë¡œìš©)
        self.save_rl_training_data(session_data, session_id, timestamp, mode)
    
    def save_cv_training_data(self, session_data: Dict, session_id: str, 
                              timestamp: str, mode: str):
        """
        CV í›ˆë ¨ ë°ì´í„° ì €ì¥ (ì œì´ê°€ YOLOv8 í›ˆë ¨ì— ì‚¬ìš©)
        
        í˜•ì‹:
        - frames/: í”„ë ˆì„ ì´ë¯¸ì§€ë“¤ (ë‚˜ì¤‘ì— Canvasì—ì„œ ìº¡ì²˜)
        - annotations.json: YOLO í˜•ì‹ ì–´ë…¸í…Œì´ì…˜
        """
        cv_file = self.cv_training_dir / f"{timestamp}_{session_id}_cv.json"
        
        # í”„ë ˆì„ë³„ ê°ì²´ ìœ„ì¹˜ ì €ì¥
        cv_data = {
            'session_id': session_id,
            'timestamp': timestamp,
            'mode': mode,
            'frames': []
        }
        
        for frame in session_data.get('frames', []):
            game_state = frame.get('gameState', {})
            
            # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (x_center, y_center, width, height, normalized)
            annotations = []
            
            # í”Œë ˆì´ì–´
            if 'player' in game_state:
                player = game_state['player']
                annotations.append({
                    'class': 0,  # Player
                    'class_name': 'player',
                    'bbox': self.normalize_bbox(
                        player.get('x', 0), 
                        player.get('y', 0), 
                        40, 40  # í”Œë ˆì´ì–´ í¬ê¸°
                    )
                })
            
            # ì¥ì• ë¬¼ë“¤
            for obs in game_state.get('obstacles', []):
                annotations.append({
                    'class': 1,  # Obstacle
                    'class_name': 'obstacle',
                    'bbox': self.normalize_bbox(
                        obs.get('x', 0), 
                        obs.get('y', 0), 
                        40, 40  # ì¥ì• ë¬¼ í¬ê¸°
                    )
                })
            
            cv_data['frames'].append({
                'frame_id': frame.get('timestamp'),
                'annotations': annotations
            })
        
        with open(cv_file, 'w') as f:
            json.dump(cv_data, f, indent=2)
        
        print(f"   ğŸ“¸ CV í›ˆë ¨ ë°ì´í„° ì €ì¥: {len(cv_data['frames'])} frames")
    
    def save_rl_training_data(self, session_data: Dict, session_id: str, 
                              timestamp: str, mode: str):
        """
        RL í›ˆë ¨ ë°ì´í„° ì €ì¥ (í´ë¡œê°€ PPO/DQN í›ˆë ¨ì— ì‚¬ìš©)
        
        í˜•ì‹:
        - state-action-reward-next_state (SARS) íŠœí”Œë“¤
        - ì—í”¼ì†Œë“œ ì •ë³´
        """
        rl_file = self.rl_training_dir / f"{timestamp}_{session_id}_rl.json"
        
        rl_data = {
            'session_id': session_id,
            'timestamp': timestamp,
            'mode': mode,
            'episode': {
                'total_reward': session_data.get('finalScore', 0),
                'steps': len(session_data.get('frames', [])),
                'survival_time': session_data.get('finalSurvivalTime', 0)
            },
            'transitions': []
        }
        
        frames = session_data.get('frames', [])
        actions = session_data.get('actions', [])
        
        # State-Action-Reward-Next_State íŠœí”Œ ìƒì„±
        for i in range(len(frames) - 1):
            current_frame = frames[i]
            next_frame = frames[i + 1]
            
            # í•´ë‹¹ í”„ë ˆì„ì˜ ì•¡ì…˜ ì°¾ê¸°
            action = self.find_action_for_frame(
                current_frame.get('timestamp'),
                actions
            )
            
            # ë³´ìƒ ê³„ì‚°
            reward = self.calculate_reward(
                current_frame.get('gameState', {}),
                next_frame.get('gameState', {})
            )
            
            transition = {
                'state': self.extract_state_vector(current_frame.get('gameState', {})),
                'action': action,
                'reward': reward,
                'next_state': self.extract_state_vector(next_frame.get('gameState', {})),
                'done': next_frame.get('gameState', {}).get('game_over', False)
            }
            
            rl_data['transitions'].append(transition)
        
        with open(rl_file, 'w') as f:
            json.dump(rl_data, f, indent=2)
        
        print(f"   ğŸ¤– RL í›ˆë ¨ ë°ì´í„° ì €ì¥: {len(rl_data['transitions'])} transitions")
    
    def normalize_bbox(self, x: float, y: float, w: float, h: float) -> List[float]:
        """
        ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
        
        Returns:
            [x_center, y_center, width, height] (0-1 ë²”ìœ„)
        """
        canvas_width = 640
        canvas_height = 480
        
        x_center = (x + w / 2) / canvas_width
        y_center = (y + h / 2) / canvas_height
        norm_width = w / canvas_width
        norm_height = h / canvas_height
        
        return [x_center, y_center, norm_width, norm_height]
    
    def extract_state_vector(self, game_state: Dict) -> List[float]:
        """
        ê²Œì„ ìƒíƒœë¥¼ RL ì…ë ¥ ë²¡í„°ë¡œ ë³€í™˜
        
        Returns:
            8ì°¨ì› ìƒíƒœ ë²¡í„° (í´ë¡œê°€ PPO/DQNì— ì‚¬ìš©)
        """
        player = game_state.get('player', {})
        obstacles = game_state.get('obstacles', [])
        
        # í”Œë ˆì´ì–´ ì •ë³´
        player_x = player.get('x', 320) / 640  # ì •ê·œí™”
        player_y = player.get('y', 240) / 480
        player_vy = player.get('vy', 0) / 20  # ì†ë„ ì •ê·œí™”
        
        # ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼ ì •ë³´
        if obstacles:
            nearest_obs = min(obstacles, 
                            key=lambda o: abs(o.get('y', 0) - player.get('y', 0)))
            obs_x = nearest_obs.get('x', 320) / 640
            obs_y = nearest_obs.get('y', 0) / 480
            distance = np.sqrt((obs_x - player_x)**2 + (obs_y - player_y)**2)
        else:
            obs_x = 0.5
            obs_y = 0.0
            distance = 1.0
        
        return [
            player_x,
            player_y,
            player_vy,
            1.0 if player.get('y', 0) >= 440 else 0.0,  # on_ground
            obs_x,
            obs_y,
            distance,
            max(0, (obs_y - player_y) / 0.1)  # time_to_collision ì¶”ì •
        ]
    
    def find_action_for_frame(self, frame_time: int, actions: List[Dict]) -> str:
        """
        í”„ë ˆì„ ì‹œê°„ì— ê°€ì¥ ê°€ê¹Œìš´ ì•¡ì…˜ ì°¾ê¸°
        """
        if not actions:
            return 'stay'
        
        closest_action = min(actions, 
                           key=lambda a: abs(a.get('timestamp', 0) - frame_time))
        return closest_action.get('action', 'stay')
    
    def calculate_reward(self, current_state: Dict, next_state: Dict) -> float:
        """
        ë³´ìƒ ê³„ì‚° (í´ë¡œì˜ RL í›ˆë ¨ìš©)
        """
        reward = 0.0
        
        # ìƒì¡´ ë³´ìƒ
        if not next_state.get('game_over', False):
            reward += 1.0
        else:
            reward -= 100.0  # ê²Œì„ ì˜¤ë²„ í˜ë„í‹°
        
        # ì ìˆ˜ ì¦ê°€ ë³´ìƒ
        score_diff = next_state.get('score', 0) - current_state.get('score', 0)
        reward += score_diff * 10.0
        
        return reward
    
    def update_stats(self, session_data: Dict):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_sessions'] += 1
        self.stats['total_frames'] += len(session_data.get('frames', []))
        self.stats['total_actions'] += len(session_data.get('actions', []))
        
        mode = session_data.get('mode', 'unknown')
        if mode == 'human':
            self.stats['human_sessions'] += 1
        elif mode == 'ai':
            self.stats['ai_sessions'] += 1
        
        self.save_stats()
    
    def load_stats(self):
        """í†µê³„ ë¡œë“œ"""
        stats_file = self.data_dir / "stats.json"
        if stats_file.exists():
            with open(stats_file, 'r') as f:
                self.stats = json.load(f)
    
    def save_stats(self):
        """í†µê³„ ì €ì¥"""
        stats_file = self.data_dir / "stats.json"
        with open(stats_file, 'w') as f:
            json.dump(self.stats, f, indent=2)
    
    def get_stats(self) -> Dict:
        """í†µê³„ ë°˜í™˜"""
        return self.stats.copy()
    
    def export_for_yolo(self, output_dir: str):
        """
        ì œì´ì˜ YOLOv8 í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ì…‹ export
        
        YOLO í‘œì¤€ í˜•ì‹:
        - images/: ì´ë¯¸ì§€ íŒŒì¼ë“¤
        - labels/: ì–´ë…¸í…Œì´ì…˜ .txt íŒŒì¼ë“¤
        - data.yaml: ë°ì´í„°ì…‹ ì„¤ì •
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        (output_path / "images").mkdir(exist_ok=True)
        (output_path / "labels").mkdir(exist_ok=True)
        
        # data.yaml ìƒì„±
        yaml_content = """
# YOLOv8 Dataset Configuration
# Generated from web gameplay data

path: {}
train: images
val: images  # TODO: Split train/val

names:
  0: player
  1: obstacle

nc: 2
""".format(str(output_path.absolute()))
        
        with open(output_path / "data.yaml", 'w') as f:
            f.write(yaml_content)
        
        print(f"âœ… YOLO ë°ì´í„°ì…‹ export ì™„ë£Œ: {output_path}")
    
    def export_for_rl(self, output_dir: str):
        """
        í´ë¡œì˜ PPO/DQN í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ì…‹ export
        
        í˜•ì‹:
        - replay_buffer.json: ëª¨ë“  transitions
        - config.json: í™˜ê²½ ì„¤ì •
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë“  RL ë°ì´í„° í•©ì¹˜ê¸°
        all_transitions = []
        for rl_file in self.rl_training_dir.glob("*.json"):
            with open(rl_file, 'r') as f:
                data = json.load(f)
                all_transitions.extend(data.get('transitions', []))
        
        replay_buffer = {
            'transitions': all_transitions,
            'size': len(all_transitions),
            'state_dim': 8,
            'action_space': ['stay', 'jump', 'left', 'right']
        }
        
        with open(output_path / "replay_buffer.json", 'w') as f:
            json.dump(replay_buffer, f, indent=2)
        
        print(f"âœ… RL ë°ì´í„°ì…‹ export ì™„ë£Œ: {output_path}")
        print(f"   ì´ transitions: {len(all_transitions)}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    collector = TrainingDataCollector()
    
    # í†µê³„ ì¶œë ¥
    stats = collector.get_stats()
    print("ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„° í†µê³„:")
    print(f"   ì´ ì„¸ì…˜: {stats['total_sessions']}")
    print(f"   ì´ í”„ë ˆì„: {stats['total_frames']}")
    print(f"   ì´ ì•¡ì…˜: {stats['total_actions']}")
    print(f"   Human ì„¸ì…˜: {stats['human_sessions']}")
    print(f"   AI ì„¸ì…˜: {stats['ai_sessions']}")

