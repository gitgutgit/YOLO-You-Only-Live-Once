# AI_model/watch_agent.py
import os
import time
import argparse
import numpy as np

from game_core import GameCore
from state_encoder import encode_state, ACTION_LIST, STATE_DIM

import cv2

import torch
from ultralytics import YOLO

# can be replaced via args
YOLO_MODEL_PATH = "yolo_fine.pt"          # fine-tuning model
PPO_MODEL_PATH = "ppo_agent.pt"           # trained ppo

#  Action index â†’ String mapping 
# 0: stay, 1: left, 2: right, 3: jump
IDX2ACTION = ACTION_LIST


def load_yolo(model_path: str):
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"YOLO model not found at {model_path}")
    print(f"âœ… Loading YOLO model from {model_path}")
    return YOLO(model_path)


def load_ppo(model_path: str):
    """Load trained PPO agent - ìƒˆ checkpoint í˜•ì‹ ì§€ì›"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"PPO agent not found at {model_path}")
    print(f"âœ… Loading PPO agent from {model_path}")
    
    # checkpoint ë¡œë“œí•´ì„œ í˜•ì‹ í™•ì¸
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    checkpoint = torch.load(model_path, map_location=device)
    
    # ìƒˆ í˜•ì‹ì¸ì§€ í™•ì¸ (lr í‚¤ê°€ ì—†ìœ¼ë©´ ìƒˆ í˜•ì‹)
    if 'lr' in checkpoint:
        # ê¸°ì¡´ í˜•ì‹: PPOAgent.load() ì‚¬ìš©
        from ppo.agent import PPOAgent
        agent = PPOAgent.load(model_path)
        return agent
    else:
        # ìƒˆ í˜•ì‹: ì§ì ‘ ë¡œë“œ
        print("   ğŸ“‚ New checkpoint format detected")
        from ppo.agent import PPOAgent
        
        # state/action ì°¨ì›
        state_dim = checkpoint.get('state_dim', STATE_DIM)
        action_dim = checkpoint.get('action_dim', len(ACTION_LIST))
        
        # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ agent ìƒì„±
        agent = PPOAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            lr=0.0001,
            gamma=0.95,
            eps_clip=0.2,
            K_epochs=10
        )
        
        # weight ë¡œë“œ
        if 'policy_state_dict' in checkpoint:
            agent.policy.load_state_dict(checkpoint['policy_state_dict'])
            agent.policy_old.load_state_dict(checkpoint['policy_state_dict'])
        if 'value_net_state_dict' in checkpoint:
            agent.value_net.load_state_dict(checkpoint['value_net_state_dict'])
        
        print(f"   âœ… Loaded: state_dim={state_dim}, action_dim={action_dim}")
        return agent


def run_visualization(yolo_path=None, ppo_path=None):
    # path 
    yolo_model_path = yolo_path or YOLO_MODEL_PATH
    ppo_model_path = ppo_path or PPO_MODEL_PATH
    
    # 1. Game/model load 
    game = GameCore()
    yolo_model = load_yolo(yolo_model_path)
    ppo_agent = load_ppo(ppo_model_path)
    
    action_counts = {name: 0 for name in ACTION_LIST}
    
    # 2. initialize
    game.reset()
    fps_delay = 1.0 / 30.0  # 30 FPS 
    
    episode_count = 0
    total_reward = 0.0
    episode_reward = 0.0

    print("ğŸ® Game Start! (q: terminate)")
    step_count = 0
    
    while True:
        # --- 1)current frame render ---
        img = game.render()              # (H, W, 3) numpy array, RGB
        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

        # --- 2) YOLO model ---
        results = yolo_model(img, verbose=False)

        detections = []
        if len(results) > 0:
            boxes = results[0].boxes
            for box in boxes:
                cls = int(box.cls[0])
                x, y, w, h = box.xywhn[0].tolist()   # normalized
                conf = float(box.conf[0])  # confidence
                detections.append({'cls': cls, 'x': x, 'y': y, 'w': w, 'h': h, 'conf': conf})
                print(cls)
                # DEBUG: Lava detection logging
                if cls == 3:
                    print(f"   ğŸŸ¡ YOLO detected: caution_lava (cls=3) at x={x:.2f}, conf={conf:.2f}")
                elif cls == 4:
                    print(f"   ğŸ”´ YOLO detected: exist_lava (cls=4) at x={x:.2f}, conf={conf:.2f}")

        # --- 3) state encoding ---
        game_state = game._get_state()
        state_vec = encode_state(detections, game_state)

        # --- 4) PPO choose behaviour (eval mode ) ---
        action_idx = ppo_agent.select_action_eval(state_vec)
        action_str = IDX2ACTION[action_idx]
        action_counts[action_str] += 1

        # --- 5) one step process ---
        _, reward, done, _ = game.step(action_str)
        episode_reward += reward

        step_count += 1

        #  Debugging:
        if step_count % 10 == 0:
            print(f"\nğŸ“Š Step {step_count}")
            print(f"   Player: x={state_vec[0]:.2f}, y={state_vec[1]:.2f}")
            # New Indices (26-dim): Meteor 1 is at [2-6] (dx, dy, dist, vx, vy)
            print(f"   Meteor 1: dx={state_vec[2]:.2f}, dy={state_vec[3]:.2f}, dist={state_vec[4]:.2f}, vx={state_vec[5]:.2f}, vy={state_vec[6]:.2f}")
            print(f"   Meteor 2: dist={state_vec[9]:.2f}")
            print(f"   Meteor 3: dist={state_vec[14]:.2f}")
            # Star info (indices 17-19)
            print(f"   Star: dx={state_vec[17]:.2f}, dy={state_vec[18]:.2f}, dist={state_vec[19]:.2f}")
            # Lava info (indices 20-22)
            lava_warning = state_vec[20]
            lava_active = state_vec[21]
            lava_dx = state_vec[22]
            lava_status = "ACTIVEğŸ”¥" if lava_active else ("WARNINGâš ï¸" if lava_warning else "inactive")
            print(f"   Lava: status={lava_status}, dx={lava_dx:.2f}")
            print(f"   On Ground: {state_vec[23]:.0f}") # Index 23 is ground
            print(f"   Action: {action_str}")
            print(f"   Reward: {reward:.2f}")

        # ë©”í…Œì˜¤ê°€ ê°€ê¹Œìš°ë©´ ì›Œë‹ë§Œ ì¶œë ¥ (í–‰ë™ì€ PPO ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        # Check all 3 meteors (indices: 4, 9, 14)
        min_dist = min(state_vec[4], state_vec[9], state_vec[14])
        if min_dist < 0.15:
            print(f"   âš ï¸ METEOR CLOSE! (dist={min_dist:.2f}) â†’ Action: {action_str}")
        
        # ë¼ë°”ê°€ í™œì„±í™”ë˜ë©´ ì›Œë‹ ì¶œë ¥
        if state_vec[21] == 1.0:  # lava_active
            lava_dx = state_vec[22]
            if abs(lava_dx) < 0.4:
                print(f"   ğŸ”¥ LAVA ACTIVE NEARBY! (dx={lava_dx:.2f}) â†’ Action: {action_str}")
        elif state_vec[20] == 1.0:  # lava_warning
            lava_dx = state_vec[22]
            if abs(lava_dx) < 0.5:
                print(f"   âš ï¸ LAVA WARNING! (dx={lava_dx:.2f}) â†’ Action: {action_str}")

        # --- 6) ì‹œê°í™”ìš© ë°•ìŠ¤/í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ---
        H, W, _ = img_bgr.shape
        for d in detections:
            cls = d["cls"]
            cx = d["x"] * W
            cy = d["y"] * H
            w = d["w"] * W
            h = d["h"] * H
            x1 = int(cx - w / 2)
            y1 = int(cy - h / 2)
            x2 = int(cx + w / 2)
            y2 = int(cy + h / 2)

            if cls == 0:
                color = (255, 0, 0)       # Player
                label = "Player"
            elif cls == 1:
                color = (0, 0, 255)       # Meteor
                label = "Meteor"
            elif cls == 2:
                color = (0, 255, 255)     # Star
                label = "Star"
            # elif cls == 3:
            #     color = (0, 165, 255)     # Caution Lava
            #     label = "Caution Lava"
            elif cls == 3 or cls ==4:
                color = (0, 140, 255)     # Lava
                label = "Lava"
            else:
                color = (255, 255, 255)
                label = f"cls{cls}"

            cv2.rectangle(img_bgr, (x1, y1), (x2, y2), color, 2)
            cv2.putText(
                img_bgr,
                label,
                (x1, max(y1 - 5, 0)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                color,
                1,
                cv2.LINE_AA,
            )

        # Current reaction & Reward
        cv2.putText(
            img_bgr,
            f"Action: {action_str}   Reward: {reward:.2f}",
            (10, 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2,
            cv2.LINE_AA,
        )

        # Score & Episdoe information
        cv2.putText(
            img_bgr,
            f"Score: {game.score}   Episode: {episode_count}",
            (10, 50),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),
            2,
            cv2.LINE_AA,
        )

        # HPbar
        cv2.putText(
            img_bgr,
            f"Health: {game.player_health}/100",
            (10, 80),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 255),
            2,
            cv2.LINE_AA,
        )

        # --- 7) í™”ë©´ ì¶œë ¥ ---
        cv2.imshow("PPO Agent Playing (Vision-based)", img_bgr)

        key = cv2.waitKey(int(fps_delay * 1000))
        if key == ord('q'):
            break

        if done:
            # ì—í”¼ì†Œë“œ ì¢…ë£Œ
            episode_count += 1
            total_reward += episode_reward
            avg_reward = total_reward / episode_count if episode_count > 0 else 0.0
            
            print(f"ğŸ’€ Episode {episode_count} finished!")
            print(f"   Score: {game.score}")
            print(f"   Episode Reward: {episode_reward:.2f}")
            print(f"   Average Reward: {avg_reward:.2f}")
            print(f"   Resetting in 1.5s...")
            print(f"   Actions: {action_counts}")
            time.sleep(1.5)
            game.reset()
            episode_reward = 0.0
            

    cv2.destroyAllWindows()
    
    # âœ… stat print
    print("\n" + "="*50)
    print("ğŸ® Game Statistics")
    print("="*50)
    print(f"Total Episodes: {episode_count}")
    avg_ep_reward = total_reward / episode_count if episode_count > 0 else 0.0
    print(f"Average Reward: {avg_ep_reward:.2f}")
    print(f"Action Counts: {action_counts}")
    print("="*50)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Watch PPO Agent Play")
    parser.add_argument("--model", type=str, default="ppo_agent.pt",
                        help="PPO model path (e.g., ppo_agent_ep100.pt)")
    parser.add_argument("--yolo", type=str, default="yolo_fine.pt",
                        help="YOLO model path")
    args = parser.parse_args()
    
    run_visualization(yolo_path=args.yolo, ppo_path=args.model)
